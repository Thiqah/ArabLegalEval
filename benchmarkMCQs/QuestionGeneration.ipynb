{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "762e5484",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/low_level/evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa530a77-b0a7-46f1-bb17-0cfa31650c60",
   "metadata": {},
   "source": [
    "# Building Evaluation from Scratch\n",
    "\n",
    "We show how you can build evaluation modules from scratch. This includes both evaluation of the final generated response (where the output is plain text), as well as the evaluation of retrievers (where the output is a ranked list of items).\n",
    "\n",
    "We have in-house modules in our [Evaluation](https://gpt-index.readthedocs.io/en/latest/core_modules/supporting_modules/evaluation/root.html) section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69705b2b-38f4-471e-bccf-f3bac26f1582",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We load some data and define a very simple RAG query engine that we'll evaluate (uses top-k retrieval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aeaaad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama-index-readers-file pymupdf\n",
    "# %pip install llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64bec520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9883cde-bf3e-40a7-8a2e-59f39daeadc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter, SimpleNodeParser\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "402c7ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'QUESTION_GEN_SYS_TMPL': 'You are a law Professor.\\nYour task is to setup {num_questions_per_chunk} questions for an upcoming quiz.\\nThe questions should be diverse in nature across the document.\\nRestrict the questions to the context information provided.\\nThe questions should be in Arabic.\\n',\n",
       " 'QUESTION_GEN_SYS_TMPL_V2': 'You are a law Professor.\\nYour task is to setup {num_questions_per_chunk} questions for an upcoming quiz.\\nThe questions should be diverse in nature across the document.\\nRestrict the questions to the context information provided.\\nA student should be able to answer your questions using only the context information.\\nAvoid asking about dates or specific numbers.\\nAsk short questions only\\nQuesitons should be solvable with short answers\\nThe questions should be in Arabic.\\n',\n",
       " 'QUESTION_GEN_USER_TMPL': 'Context information is below.\\n---------------------\\n{context_str}\\n---------------------\\nGiven the context information and not prior knowledge, generate the relevant questions.\\n',\n",
       " 'QA_PROMPT': 'Context information is below.\\n---------------------\\n{context_str}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query in Arabic.\\nQuery: {query_str}\\nAnswer:\\n',\n",
       " 'QA_PROMPT_V2': 'Context information is below.\\n---------------------\\n{context_str}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query in Arabic.\\nThe answer should be concise and to the point, make it as short as possible.\\nAvoid answering with lists or numbered points.\\nGive short and direct answers only.\\nQuery: {query_str}\\nAnswer:\\n',\n",
       " 'MCQ_QUESTION_DELIMITER': '####',\n",
       " 'MCQ_PROMPT': 'السؤال: {question}\\n\\nالإجابة الصحيحة: {correct_answer}\\n\\nالخيارات:\\n{options}\\n####\\n',\n",
       " 'MCQ_QUESTION_GEN_SYS_TMPL': 'You are a law Professor.\\nYour task is to setup {num_questions_per_chunk} question/s for an upcoming quiz.\\nThe questions should be diverse in nature across the document.\\nRestrict the questions to the context information provided.\\nThe questions must be multiple choice questions.\\nThe distractors should be plausible and tricky, but obviously incorrect.\\nA student should be able to answer your questions using only the context information.\\nAvoid asking about dates or specific numbers.\\nThe correct answer should always be the first option.\\nFor each question, provide 3 distractors in addition to the correct answer.\\nThe questions should be in Arabic.\\nEnd each example question with ####.\\n\\nYour questions should have simmilar style and format to the following examples:\\n\\n{few_shot_examples}\\n',\n",
       " 'BAD_MCQ_QUESTION_GEN_SYS_TMPL': 'You are a law Professor.\\nYour task is to setup {num_questions_per_chunk} questions for an upcoming quiz.\\nThe questions should be diverse in nature across the document.\\nRestrict the questions to the context information provided.\\nThe questions must be multiple choice questions.\\nThe questions should be difficult and tricky.\\nMake the distractors as tricky and ambiguous as possible.\\nThe correct answer should always be the first option.\\nThe questions should be in Arabic.\\nEnd each example question with ####.\\n\\nYour questions should have simmilar style and format to the following examples:\\n\\n{few_shot_examples}\\n',\n",
       " 'MCQ_QUESTION_GEN_USER_TMPL': 'Context information is below.\\n---------------------\\n{context_str}\\n---------------------\\nGiven the context information and not prior knowledge, generate relevant questions.\\n',\n",
       " 'QA_CORRECTNESS_SYS_TMPL': 'You are an expert evaluation system for a question answering chatbot.\\n\\nYou are given the following information:\\n- a user query,\\n- a reference answer, and\\n- a generated answer.\\n\\nYour job is to judge the relevance and correctness of the generated answer.\\nOutput a single score that represents a holistic evaluation.\\nYou must return your response in a line with only the score.\\nDo not return answers in any other format.\\nOn a separate line provide your reasoning for the score as well.\\n\\nFollow these guidelines for scoring:\\n- Your score has to be between 1 and 5, where 1 is the worst and 5 is the best.\\n- If the generated answer is not relevant to the user query,\\nyou should give a score of 1.\\n- If the generated answer is relevant but contains mistakes,\\nyou should give a score between 2 and 3.\\n- If the generated answer is relevant and fully correct,\\nyou should give a score between 4 and 5.\\n',\n",
       " 'QA_CORRECTNESS_USER_TMPL': '## User Query\\n{query}\\n\\n## Reference Answer\\n{reference_answer}\\n\\n## Generated Answer\\n{generated_answer}\\n',\n",
       " 'EVAL_TEMPLATE': \"Please tell if a given piece of information is supported by the context.\\nYou need to answer with either YES or NO.\\nAnswer YES if any of the context supports the information, even if most of the context is unrelated. Some examples are provided below.\\n\\nInformation: Apple pie is generally double-crusted.\\nContext: An apple pie is a fruit pie in which the principal filling ingredient is apples.\\nApple pie is often served with whipped cream, ice cream ('apple pie à la mode'), custard or cheddar cheese.\\nIt is generally double-crusted, with pastry both above and below the filling; the upper crust may be solid or latticed (woven of crosswise strips).\\nAnswer: YES\\nInformation: Apple pies tastes bad.\\nContext: An apple pie is a fruit pie in which the principal filling ingredient is apples.\\nApple pie is often served with whipped cream, ice cream ('apple pie à la mode'), custard or cheddar cheese.\\nIt is generally double-crusted, with pastry both above and below the filling; the upper crust may be solid or latticed (woven of crosswise strips).\\nAnswer: NO\\nInformation: {query_str}\\nContext: {context_str}\\nAnswer:\\n\",\n",
       " 'EVAL_REFINE_TEMPLATE': 'We want to understand if the following information is present in the context information: {query_str}\\nWe have provided an existing YES/NO answer: {existing_answer}\\nWe have the opportunity to refine the existing answer (only if needed) with some more context below.\\n------------\\n{context_msg}\\n------------\\nIf the existing answer was already YES, still answer YES. If the information is present in the new context, answer YES. Otherwise answer NO.\\n',\n",
       " 'QA_TO_MCQ_COT_PROMPT': 'You are a law Professor.\\nYou have a bank of questions that are in the form of question-answer pairs.\\nYour task is to convert the question-answer pairs to multiple choice questions.\\nThe distractors should be plausible and tricky, and similar to the style of the answer.\\nMake sure all distractors are incorrect by comparing them agains the answer.\\nIf the answer is too long, shotren it to a reasonable length, similar to the length of the distractors, by making the answer direct.\\nThe questions are in Arabic.\\nFor the following question and answer:\\nQuestion: {question}\\nAnswer: {answer}\\nWrite a multiple choice question with the correct answer and three distractors in the following format:\\n\\n<start_thought>\\n\"A space for you to think step by step about 3 incorrect distractors, do it in Arabic\"\\n<end_thought>\\n\\n\"Repeat the quesiton\"\\n\\n1-\"Correct Answer\"\\n2-\"Distractor 1\"\\n3-\"Distractor 2\"\\n4-\"Distractor 3\"\\n',\n",
       " 'QA_TO_MCQ_PROMPT': 'You are a law Professor.\\nYou have a bank of questions that are in the form of question-answer pairs.\\nYour task is to convert the question-answer pairs to multiple choice questions.\\nThe distractors should be plausible and tricky, and similar to the style of the answer.\\nMake sure all distractors are incorrect.\\nIf the answer is too long, shotren it to a reasonable length, similar to the length of the distractors, by making the answer direct.\\nThe questions are in Arabic.\\nFor the following question and answer:\\nQuestion: {question}\\nAnswer: {answer}\\nWrite a multiple choice question with the correct answer and three distractors in the following format:\\n\\n\"Repeat the quesiton\"\\n\\n1-\"Correct Answer\"\\n2-\"Distractor 1\"\\n3-\"Distractor 2\"\\n4-\"Distractor 3\"\\n',\n",
       " 'FILTER_MCQ_PROMPT': 'You are a law Professor.\\nYou have a bank of multiple choice questions.\\nYour task is to filter out the questions that are not relevant to the context information provided.\\nThe questions are in Arabic.\\nFor the following context and question:\\nQuestion: {question}\\n\\nAnswer the following:\\n- Is the question relevant to the context information? 0 for NO, 1 for YES\\n- Are the ditractors for the question all incorrect? 0 for NO, 1 for YES\\n- Is the correct answer the first option? 0 for NO, 1 for YES\\n- Does the question need the provided context to be answered? 0 for NO, 1 for YES\\n- Are all the distractors unique? 0 for NO, 1 for YES\\n\\nProvide the answers in the following format:\\nquestion_relevance: 0/1\\ndistractors_correctness: 0/1\\ncorrect_answer_first: 0/1\\ncontext_needed: 0/1\\nunique_distractors: 0/1\\ntotal_score: 0-5\\n'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load yaml file\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "config = EasyDict(yaml.safe_load(open(\"defaults.yaml\")))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b6a360d-ea79-444e-9f0f-cfcca9fb9642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Country</th>\n",
       "      <th>Group</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Level</th>\n",
       "      <th>Question</th>\n",
       "      <th>Context</th>\n",
       "      <th>Answer Key</th>\n",
       "      <th>Option 1</th>\n",
       "      <th>Option 2</th>\n",
       "      <th>Option 3</th>\n",
       "      <th>Option 4</th>\n",
       "      <th>Option 5</th>\n",
       "      <th>is_few_shot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://folderat.com/Reference/1649/%D8%A3%D8%...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>Islamic Studies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>كم عدد سور القرآن الكريم؟</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>111</td>\n",
       "      <td>112</td>\n",
       "      <td>113</td>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://folderat.com/Reference/1649/%D8%A3%D8%...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>Islamic Studies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>في أي الأيام خلق سيدنا آدم عليه السلام؟</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>يوم السبت</td>\n",
       "      <td>يوم الاثنين</td>\n",
       "      <td>يوم الأربعاء</td>\n",
       "      <td>يوم الجمعة</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://folderat.com/Reference/1649/%D8%A3%D8%...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>Islamic Studies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>كم عدد السنوات التي نام فيها أهل الكهف؟</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>300 سنة</td>\n",
       "      <td>309 سنوات</td>\n",
       "      <td>400 سنة</td>\n",
       "      <td>409 سنوات</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://folderat.com/Reference/1649/%D8%A3%D8%...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>Islamic Studies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>اسم أول صحابي قرأ القرآن جهرة؟</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>عبد الله بن مسعود</td>\n",
       "      <td>عبد الله بن عباس</td>\n",
       "      <td>عبد الله بن عمرو بن العاص</td>\n",
       "      <td>عبد الله بن الزبير</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://folderat.com/Reference/1649/%D8%A3%D8%...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Humanities</td>\n",
       "      <td>Islamic Studies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>من هي أخر زوجات النبي التي توفيت؟</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>السيدة زينب بنت جحش</td>\n",
       "      <td>السيدة عائشة بنت أبي بكر</td>\n",
       "      <td>السيدة أم سلمة</td>\n",
       "      <td>السيدة سودة بنت زمعة</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14570</th>\n",
       "      <td>14570</td>\n",
       "      <td>exams-28a8e94f-7722-11ea-9116-54bef70b159e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social Science</td>\n",
       "      <td>Civics</td>\n",
       "      <td>High</td>\n",
       "      <td>شهدت دولة قطر نقلة نوعية في حرية الرأي وذلك من...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>إنشاء الهيئة العامة للإذاعة والتلفزيون</td>\n",
       "      <td>الانضمام لمجلس التعاون الخليجي</td>\n",
       "      <td>قرار إلغاء وزارة الإعلام</td>\n",
       "      <td>انتخابات المجلس البلدي المركزي</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14571</th>\n",
       "      <td>14571</td>\n",
       "      <td>exams-28a8e950-7722-11ea-9116-54bef70b159e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social Science</td>\n",
       "      <td>Civics</td>\n",
       "      <td>High</td>\n",
       "      <td>من المبادرات الوطنية القطرية للصحة:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>برنامج الطالب النظيف</td>\n",
       "      <td>برنامج دلني على فطرتي</td>\n",
       "      <td>موقع الأمن والسلامة</td>\n",
       "      <td>الجمعية الوطنية للسكري</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14572</th>\n",
       "      <td>14572</td>\n",
       "      <td>exams-28a8e994-7722-11ea-9116-54bef70b159e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social Science</td>\n",
       "      <td>Civics</td>\n",
       "      <td>High</td>\n",
       "      <td>تهدف التنمية المستدامة في العالم الإسلامي في ا...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B</td>\n",
       "      <td>توظيف الموارد من أجل رفع المستوى المعيشي للسكان.</td>\n",
       "      <td>تحقيق الاستخدام الأمثل للأراضي الزراعية.</td>\n",
       "      <td>تطوير وتنمية سكان العالم الإسلامي.</td>\n",
       "      <td>رفع مستوى الخدمات الصحية كافة المجالات .</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14573</th>\n",
       "      <td>14573</td>\n",
       "      <td>exams-28a8e9a4-7722-11ea-9116-54bef70b159e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social Science</td>\n",
       "      <td>Civics</td>\n",
       "      <td>High</td>\n",
       "      <td>تهدف التنمية المستدامة في العالم الإسلامي في ا...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>توظيف الموارد من أجل رفع المستوى المعيشي للسكان .</td>\n",
       "      <td>رفع مستوى الخدمات الصحية كافة المجالات .</td>\n",
       "      <td>تحقيق الاستخدام الأمثل للأراضي الزراعية.</td>\n",
       "      <td>تطوير وتنمية سكان العالم الإسلامي.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14574</th>\n",
       "      <td>14574</td>\n",
       "      <td>exams-28a8ea44-7722-11ea-9116-54bef70b159e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Social Science</td>\n",
       "      <td>Civics</td>\n",
       "      <td>High</td>\n",
       "      <td>\" يعد الأول في مدينة الدوحة من حيث مساحة الاست...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A</td>\n",
       "      <td>الصناعي</td>\n",
       "      <td>التجاري</td>\n",
       "      <td>الخدمي</td>\n",
       "      <td>السكني</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14575 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                             Source Country  \\\n",
       "0          0  https://folderat.com/Reference/1649/%D8%A3%D8%...     NaN   \n",
       "1          1  https://folderat.com/Reference/1649/%D8%A3%D8%...     NaN   \n",
       "2          2  https://folderat.com/Reference/1649/%D8%A3%D8%...     NaN   \n",
       "3          3  https://folderat.com/Reference/1649/%D8%A3%D8%...     NaN   \n",
       "4          4  https://folderat.com/Reference/1649/%D8%A3%D8%...     NaN   \n",
       "...      ...                                                ...     ...   \n",
       "14570  14570         exams-28a8e94f-7722-11ea-9116-54bef70b159e     NaN   \n",
       "14571  14571         exams-28a8e950-7722-11ea-9116-54bef70b159e     NaN   \n",
       "14572  14572         exams-28a8e994-7722-11ea-9116-54bef70b159e     NaN   \n",
       "14573  14573         exams-28a8e9a4-7722-11ea-9116-54bef70b159e     NaN   \n",
       "14574  14574         exams-28a8ea44-7722-11ea-9116-54bef70b159e     NaN   \n",
       "\n",
       "                Group          Subject Level  \\\n",
       "0          Humanities  Islamic Studies   NaN   \n",
       "1          Humanities  Islamic Studies   NaN   \n",
       "2          Humanities  Islamic Studies   NaN   \n",
       "3          Humanities  Islamic Studies   NaN   \n",
       "4          Humanities  Islamic Studies   NaN   \n",
       "...               ...              ...   ...   \n",
       "14570  Social Science           Civics  High   \n",
       "14571  Social Science           Civics  High   \n",
       "14572  Social Science           Civics  High   \n",
       "14573  Social Science           Civics  High   \n",
       "14574  Social Science           Civics  High   \n",
       "\n",
       "                                                Question Context Answer Key  \\\n",
       "0                              كم عدد سور القرآن الكريم؟     NaN          D   \n",
       "1                في أي الأيام خلق سيدنا آدم عليه السلام؟     NaN          D   \n",
       "2                كم عدد السنوات التي نام فيها أهل الكهف؟     NaN          B   \n",
       "3                         اسم أول صحابي قرأ القرآن جهرة؟     NaN          A   \n",
       "4                      من هي أخر زوجات النبي التي توفيت؟     NaN          C   \n",
       "...                                                  ...     ...        ...   \n",
       "14570  شهدت دولة قطر نقلة نوعية في حرية الرأي وذلك من...     NaN          B   \n",
       "14571                من المبادرات الوطنية القطرية للصحة:     NaN          B   \n",
       "14572  تهدف التنمية المستدامة في العالم الإسلامي في ا...     NaN          B   \n",
       "14573  تهدف التنمية المستدامة في العالم الإسلامي في ا...     NaN          C   \n",
       "14574  \" يعد الأول في مدينة الدوحة من حيث مساحة الاست...     NaN          A   \n",
       "\n",
       "                                                Option 1  \\\n",
       "0                                                    111   \n",
       "1                                              يوم السبت   \n",
       "2                                                300 سنة   \n",
       "3                                      عبد الله بن مسعود   \n",
       "4                                    السيدة زينب بنت جحش   \n",
       "...                                                  ...   \n",
       "14570             إنشاء الهيئة العامة للإذاعة والتلفزيون   \n",
       "14571                               برنامج الطالب النظيف   \n",
       "14572   توظيف الموارد من أجل رفع المستوى المعيشي للسكان.   \n",
       "14573  توظيف الموارد من أجل رفع المستوى المعيشي للسكان .   \n",
       "14574                                            الصناعي   \n",
       "\n",
       "                                       Option 2  \\\n",
       "0                                           112   \n",
       "1                                   يوم الاثنين   \n",
       "2                                     309 سنوات   \n",
       "3                              عبد الله بن عباس   \n",
       "4                      السيدة عائشة بنت أبي بكر   \n",
       "...                                         ...   \n",
       "14570            الانضمام لمجلس التعاون الخليجي   \n",
       "14571                     برنامج دلني على فطرتي   \n",
       "14572  تحقيق الاستخدام الأمثل للأراضي الزراعية.   \n",
       "14573  رفع مستوى الخدمات الصحية كافة المجالات .   \n",
       "14574                                   التجاري   \n",
       "\n",
       "                                       Option 3  \\\n",
       "0                                           113   \n",
       "1                                  يوم الأربعاء   \n",
       "2                                       400 سنة   \n",
       "3                     عبد الله بن عمرو بن العاص   \n",
       "4                                السيدة أم سلمة   \n",
       "...                                         ...   \n",
       "14570                  قرار إلغاء وزارة الإعلام   \n",
       "14571                       موقع الأمن والسلامة   \n",
       "14572        تطوير وتنمية سكان العالم الإسلامي.   \n",
       "14573  تحقيق الاستخدام الأمثل للأراضي الزراعية.   \n",
       "14574                                    الخدمي   \n",
       "\n",
       "                                       Option 4 Option 5  is_few_shot  \n",
       "0                                           114      NaN            0  \n",
       "1                                    يوم الجمعة      NaN            0  \n",
       "2                                     409 سنوات      NaN            0  \n",
       "3                            عبد الله بن الزبير      NaN            0  \n",
       "4                          السيدة سودة بنت زمعة      NaN            0  \n",
       "...                                         ...      ...          ...  \n",
       "14570            انتخابات المجلس البلدي المركزي      NaN            0  \n",
       "14571                    الجمعية الوطنية للسكري      NaN            0  \n",
       "14572  رفع مستوى الخدمات الصحية كافة المجالات .      NaN            0  \n",
       "14573        تطوير وتنمية سكان العالم الإسلامي.      NaN            0  \n",
       "14574                                    السكني      NaN            0  \n",
       "\n",
       "[14575 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "if os.path.exists('sources/ArabicMMLU.csv'):\n",
    "    arabicmmlu_df = pd.read_csv('sources/ArabicMMLU.csv')\n",
    "else:\n",
    "    arabicMMLU = load_dataset('MBZUAI/ArabicMMLU')\n",
    "    arabicmmlu_df = arabicMMLU['test'].to_pandas()\n",
    "    arabicmmlu_df.to_csv('source/ArabicMMLU.csv', index=False)\n",
    "    \n",
    "\n",
    "arabicmmlu_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b422d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SimpleNodeParser.from_defaults(chunk_size=1e6)\n",
    "\n",
    "\n",
    "\n",
    "def convert_qa_to_string(row) -> str:\n",
    "    options = list(map(str.strip, filter(lambda x: x not in [None, np.nan, 'nan'], [\n",
    "       str(row[f\"Option {i}\"]) for i in range(1, 6)\n",
    "    ])))\n",
    "    options_str = \"\\n\".join(\n",
    "        f\"{i+1}. {x}\" for i, x in enumerate(options)\n",
    "    )\n",
    "    answer_key_map = {\n",
    "        \"A\": 0,\n",
    "        \"B\": 1,\n",
    "        \"C\": 2,\n",
    "        \"D\": 3,\n",
    "        \"E\": 4,\n",
    "    }\n",
    "    correct_answer_str = options[answer_key_map[row[\"Answer Key\"]]]\n",
    "\n",
    "    return config.MCQ_PROMPT.format(\n",
    "        question=row['Question'],\n",
    "        options=options_str,\n",
    "        correct_answer=correct_answer_str\n",
    "    )\n",
    "\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        text=convert_qa_to_string(row),\n",
    "        metadata=row.to_dict()\n",
    "    ) for _, row in arabicmmlu_df.query('Subject==\"Law\"').iterrows()\n",
    "]\n",
    "\n",
    "arabicmmlu_nodes = node_parser.get_nodes_from_documents(\n",
    "    documents,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "287da53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5751, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parent</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Section</th>\n",
       "      <th>Description</th>\n",
       "      <th>Tables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>المادة الأولى</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>يقصد بالألفاظ والعبارات الآتية – أينما وردت في...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>المادة الثانية</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>١- تقدم مذكرة الاعتراض إلى محكمة الدرجة الأولى...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>المادة الثالثة</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>١- للدائرة مصدرة الحكم الاطلاع على مذكرة الاعت...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>المادة الرابعة</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>الغائب المحكوم عليه الوارد في الفقرة (٤) من ال...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>المادة الخامسة</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>١- طلب الاستئناف ينقل الدعوى بحالتها التي كانت...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Parent  Chapter  Section  \\\n",
       "0   المادة الأولى      NaN      NaN   \n",
       "1  المادة الثانية      NaN      NaN   \n",
       "2  المادة الثالثة      NaN      NaN   \n",
       "3  المادة الرابعة      NaN      NaN   \n",
       "4  المادة الخامسة      NaN      NaN   \n",
       "\n",
       "                                         Description Tables  \n",
       "0  يقصد بالألفاظ والعبارات الآتية – أينما وردت في...     []  \n",
       "1  ١- تقدم مذكرة الاعتراض إلى محكمة الدرجة الأولى...     []  \n",
       "2  ١- للدائرة مصدرة الحكم الاطلاع على مذكرة الاعت...     []  \n",
       "3  الغائب المحكوم عليه الوارد في الفقرة (٤) من ال...     []  \n",
       "4  ١- طلب الاستئناف ينقل الدعوى بحالتها التي كانت...     []  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moj_df = pd.read_csv('sources/MOJ_Regulations.csv')\n",
    "print(moj_df.shape)\n",
    "moj_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b5d757f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(338, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>رقم التعميم</th>\n",
       "      <th>موضوعه</th>\n",
       "      <th>تاريخه</th>\n",
       "      <th>نص التعميم</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109/1/ك</td>\n",
       "      <td>حوادث السيارات</td>\n",
       "      <td>1392/7/3</td>\n",
       "      <td>وبعد: (فنشير إلى خطاب صاحب السمو الملكي نائب و...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109/1/ك</td>\n",
       "      <td>الديـات</td>\n",
       "      <td>1392/7/3</td>\n",
       "      <td>وبعد: (فنشير إلى خطاب صاحب السمو الملكي نائب و...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109/1/ك</td>\n",
       "      <td>الطب</td>\n",
       "      <td>1392/7/3</td>\n",
       "      <td>- وبعد: (فنشير إلى خطاب صاحب السمو الملكي نائب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109/1/ك</td>\n",
       "      <td>قتل الخطأ</td>\n",
       "      <td>1392/7/3</td>\n",
       "      <td>- وبعد: (فنشير إلى خطاب صاحب السمو الملكي نائب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114/3/ت</td>\n",
       "      <td>حوادث السيارات</td>\n",
       "      <td>1398/6/21</td>\n",
       "      <td>وبعد: (نشير إلى خطاب سماحة الرئيس العام لإدارا...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  رقم التعميم          موضوعه     تاريخه  \\\n",
       "0     109/1/ك  حوادث السيارات   1392/7/3   \n",
       "1     109/1/ك         الديـات   1392/7/3   \n",
       "2     109/1/ك            الطب   1392/7/3   \n",
       "3     109/1/ك       قتل الخطأ   1392/7/3   \n",
       "4     114/3/ت  حوادث السيارات  1398/6/21   \n",
       "\n",
       "                                          نص التعميم  \n",
       "0  وبعد: (فنشير إلى خطاب صاحب السمو الملكي نائب و...  \n",
       "1  وبعد: (فنشير إلى خطاب صاحب السمو الملكي نائب و...  \n",
       "2  - وبعد: (فنشير إلى خطاب صاحب السمو الملكي نائب...  \n",
       "3  - وبعد: (فنشير إلى خطاب صاحب السمو الملكي نائب...  \n",
       "4  وبعد: (نشير إلى خطاب سماحة الرئيس العام لإدارا...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tameem_df = pd.read_csv('sources/tameem.csv')\n",
    "print(tameem_df.shape)\n",
    "tameem_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "478f852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "moj_docs = [ \n",
    "            Document(\n",
    "                text=row['Description'],\n",
    "                metadata=row.drop('Description').to_dict()\n",
    "            ) for _, row in moj_df.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb50930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tameem_docs = [\n",
    "    Document(\n",
    "        text=row['نص التعميم'],\n",
    "        metadata=row.drop('نص التعميم').to_dict()\n",
    "    ) for _, row in tameem_df.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aaba424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6089"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_docs = moj_docs + tameem_docs\n",
    "len(source_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eada386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama index format\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.llms.anthropic import Anthropic\n",
    "AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "CLAUDE_API_KEY = os.getenv(\"CLAUDE_API_KEY\")\n",
    "api_version = \"2024-02-15-preview\"\n",
    "\n",
    "llm_gpt4 = AzureOpenAI(\n",
    "    engine=\"gpt-4\",\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "llm_claude3 = Anthropic(\n",
    "    'claude-3-opus-20240229',\n",
    "    api_key=CLAUDE_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4de6d37e-dc23-43a2-9d47-605d5978c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SentenceSplitter(chunk_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4868a75-0a1c-486c-81b1-bea989e62591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "OPENAI_API_KEY= os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from llama_index.core import Settings\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import PromptTemplate, ServiceContext, StorageContext, VectorStoreIndex, load_index_from_storage\n",
    "\n",
    "embed_model = OpenAIEmbedding(model='text-embedding-3-large', api_key=OPENAI_API_KEY)\n",
    "\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138aae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = llm_claude3\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path='./chroma_db')\n",
    "# Traditional VDB\n",
    "try:\n",
    "    chroma_collection = chroma_client.get_collection(f'ArabicMMLU_legal')\n",
    "except Exception as e:\n",
    "    print(\"Creating new collection\")\n",
    "    chroma_collection = chroma_client.create_collection('ArabicMMLU_legal')\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "arabicmmlu_index = VectorStoreIndex(\n",
    "    arabicmmlu_nodes,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model,\n",
    "    use_async=False,\n",
    "    show_progress=True,\n",
    ")\n",
    "# arabicmmlu_retriever = arabicmmlu_index.as_retriever(\n",
    "#     similarity_top_k=3,\n",
    "#     embed_model=embed_model,\n",
    "# )\n",
    "# # Sentence window retrieval\n",
    "# query_engine_sentence_window = index_sentence_window.as_query_engine(\n",
    "#     text_qa_template=text_qa_template, similarity_top_k=3, embed_model=embed_model, llm=llm\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ea82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SentenceSplitter(chunk_size=1e6, chunk_overlap=0)\n",
    "\n",
    "nodes = node_parser.get_nodes_from_documents(\n",
    "    source_docs,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b60e745-aae4-4ab2-be7d-563a883d27a3",
   "metadata": {},
   "source": [
    "## Dataset Generation\n",
    "\n",
    "We first go through an exercise of generating a synthetic evaluation dataset. We do this by synthetically generating a set of questions from existing context. We then run each question with existing context through a powerful LLM (e.g. GPT-4) to generate a \"ground-truth\" response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b4f0bf-8f7d-4693-b055-d050020b1291",
   "metadata": {},
   "source": [
    "### Define Functions\n",
    "\n",
    "We define the functions that we will use for dataset generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a305907-14d1-4f5c-a15c-145ae7dcb3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import BaseNode\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.llms import ChatMessage, MessageRole\n",
    "from llama_index.core import ChatPromptTemplate, PromptTemplate\n",
    "from typing import Tuple, List\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "from multiprocessing.pool import ThreadPool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70019ed9-bed5-434e-b6d3-545726ac7397",
   "metadata": {},
   "source": [
    "We define `generate_answers_for_questions` to generate answers from questions given context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8ca84683-5d4c-4b1f-ae4d-cd6aea51dc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_template = ChatPromptTemplate(\n",
    "    message_templates=[\n",
    "        ChatMessage(role=MessageRole.USER, content=config.QA_PROMPT),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def generate_answers_for_questions(\n",
    "    questions: List[str], context: str, llm: OpenAI\n",
    ") -> str:\n",
    "    \"\"\"Generate answers for questions given context.\"\"\"\n",
    "    \n",
    "    def generate_answer(idx, question):\n",
    "        fmt_qa_prompt = question_answer_template.format_messages(\n",
    "            context_str=context,\n",
    "            query_str=question,\n",
    "        )\n",
    "        response_obj = llm.chat(fmt_qa_prompt)\n",
    "        return response_obj.message.content\n",
    "\n",
    "    # for idx, node in enumerate(nodes):\n",
    "    answers = list(\n",
    "        tqdm(\n",
    "            ThreadPool().imap(\n",
    "                lambda x: generate_answer(*x),\n",
    "                enumerate(questions),\n",
    "            ),\n",
    "        \"generate_answers_for_questions()\",\n",
    "        total=len(questions),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c0e168-e2d4-4e63-ae77-5413499b0c7d",
   "metadata": {},
   "source": [
    "We define `generate_qa_pairs` to generate qa pairs over an entire list of Nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f1b4e96d-d08d-4c69-9b35-0dbb1f0a61b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_gen_template = ChatPromptTemplate(\n",
    "    message_templates=[\n",
    "        ChatMessage(role=MessageRole.SYSTEM, content=config.QUESTION_GEN_SYS_TMPL),\n",
    "        ChatMessage(role=MessageRole.USER, content=config.QUESTION_GEN_USER_TMPL),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def generate_qa_pairs(\n",
    "    nodes: List[BaseNode], llm: OpenAI, num_questions_per_chunk: int = 2,\n",
    "    delimiter: str = \"\\n\",\n",
    "    question_gen_template=question_gen_template,\n",
    ") -> List[Tuple[str, str]]:\n",
    "    \"\"\"Generate questions.\"\"\"\n",
    "    def process_node(idx, node):\n",
    "        context_str = node.get_content(metadata_mode=\"all\")\n",
    "        fmt_messages = question_gen_template.format_messages(\n",
    "            num_questions_per_chunk=num_questions_per_chunk,\n",
    "            context_str=context_str,\n",
    "        )\n",
    "        chat_response = llm.chat(fmt_messages)\n",
    "        raw_output = chat_response.message.content\n",
    "\n",
    "        result_list = str(raw_output).strip().split(delimiter)\n",
    "        cleaned_questions = [\n",
    "            re.sub(r\"^\\d+[\\).\\s]\", \"\", question).strip()\n",
    "            for question in result_list\n",
    "        ]\n",
    "        answers = generate_answers_for_questions(\n",
    "            cleaned_questions, context_str, llm\n",
    "        )\n",
    "        cur_qa_pairs = list(zip(cleaned_questions, answers))\n",
    "        return cur_qa_pairs\n",
    "    \n",
    "    qa_pairs = list(\n",
    "        tqdm(\n",
    "            ThreadPool().imap(\n",
    "                lambda x: process_node(*x),\n",
    "                enumerate(nodes),\n",
    "            ),\n",
    "        \"Generating QA pairs\",\n",
    "        total=len(nodes),\n",
    "        )\n",
    "    )\n",
    "    # flatten\n",
    "    qa_pairs = [item for sublist in qa_pairs for item in sublist]\n",
    "        \n",
    "    return qa_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30455ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_pairs = generate_qa_pairs(\n",
    "    nodes,\n",
    "    llm=llm_gpt4,\n",
    "    num_questions_per_chunk=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d98305",
   "metadata": {},
   "source": [
    "Converting question answer paris int MSQs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9cd1651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_to_mcq_template = ChatPromptTemplate(\n",
    "    message_templates=[\n",
    "        ChatMessage(role=MessageRole.USER, content=config.QA_TO_MCQ_PROMPT),\n",
    "    ]\n",
    ")\n",
    "qa_to_mcq_cot_template = ChatPromptTemplate(\n",
    "    message_templates=[\n",
    "        ChatMessage(role=MessageRole.USER, content=config.QA_TO_MCQ_COT_PROMPT),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9bb47b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_quesitons_to_mcqs(\n",
    "    qa_pairs: List[tuple], mcq_prompt_template: str, llm: OpenAI\n",
    ") -> str:\n",
    "    \"\"\"Converting question-answer paris into MCQs.\"\"\"\n",
    "    \n",
    "    def question_to_mcq(idx, qa_pair):\n",
    "        question, answer = qa_pair\n",
    "        prompt_template = mcq_prompt_template.format_messages(\n",
    "            question=question,\n",
    "            answer=answer,\n",
    "        )\n",
    "        response_obj = llm.chat(prompt_template)\n",
    "        return response_obj.message.content\n",
    "\n",
    "    mcqs = list(\n",
    "        tqdm(\n",
    "            ThreadPool().imap(\n",
    "                lambda x: question_to_mcq(*x),\n",
    "                enumerate(qa_pairs),\n",
    "            ),\n",
    "        \"convert_quesitons_to_mcqs()\",\n",
    "        total=len(qa_pairs),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return mcqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349f1324",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcqs = convert_quesitons_to_mcqs(\n",
    "    qa_pairs,\n",
    "    qa_to_mcq_template,\n",
    "    llm_gpt4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b541f261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_mcqs(mcqs):\n",
    "    formatted_mcqs = []\n",
    "    for example in mcqs:\n",
    "        question = example.split('\\n')[0]\n",
    "        options = example.split('\\n')[2:]\n",
    "        formatted_mcqs.append([question, options])\n",
    "    return formatted_mcqs\n",
    "\n",
    "formated_mcqs = format_mcqs(mcqs)\n",
    "formated_mcqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ecd9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_to_mcqs_dict = {}\n",
    "for i in range(len(formated_mcqs)):\n",
    "    qa_to_mcqs_dict[i] = {\n",
    "        'question': formated_mcqs[i][0],\n",
    "        'options': formated_mcqs[i][1],\n",
    "        'answer': formated_mcqs[i][1][0],\n",
    "        'context': nodes[i].text\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9c11e0",
   "metadata": {},
   "source": [
    "With Chain of Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4664ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcqs_cot = convert_quesitons_to_mcqs(\n",
    "    qa_pairs,\n",
    "    qa_to_mcq_cot_template,\n",
    "    llm_gpt4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a40849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_mcqs_cot(mcqs_cot):\n",
    "    formated_mcqs_cot = []\n",
    "    for example in mcqs_cot:\n",
    "        example = example.strip('<start_thought>').split('<end_thought>')\n",
    "\n",
    "        reasoning = example[0]\n",
    "        question = example[1].strip().split('\\n')[0]\n",
    "        options = example[1].strip().split('\\n')[2:]    \n",
    "        \n",
    "        answer = options[0]\n",
    "        formated_mcqs_cot.append([question, reasoning, options, answer])\n",
    "        \n",
    "    return formated_mcqs_cot\n",
    "\n",
    "formated_mcqs_cot = format_mcqs_cot(mcqs_cot)\n",
    "formated_mcqs_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2d7abd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_to_mcqs_cot_dict = {}\n",
    "for i in range(len(formated_mcqs_cot)):\n",
    "    qa_to_mcqs_cot_dict[i] = {\n",
    "        'question': formated_mcqs_cot[i][0],\n",
    "        'reasoning': formated_mcqs_cot[i][1],\n",
    "        'options': formated_mcqs_cot[i][2],\n",
    "        'answer': formated_mcqs_cot[i][2][0],\n",
    "        'context': nodes[i].text\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c3abef",
   "metadata": {},
   "source": [
    "#### For MCQ Generation Using In-context Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "37459d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "mcq_question_gen_template = ChatPromptTemplate(\n",
    "    message_templates=[\n",
    "        ChatMessage(role=MessageRole.SYSTEM, content=config.MCQ_QUESTION_GEN_SYS_TMPL),\n",
    "        ChatMessage(role=MessageRole.USER, content=config.MCQ_QUESTION_GEN_USER_TMPL),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def generate_mcq_pairs(\n",
    "    nodes_dict: dict,\n",
    "    num_questions_per_chunk: int = 2,\n",
    "    top_k: int = 3,\n",
    "    delimiter: str = \"####\",\n",
    "    mcq_question_gen_template=mcq_question_gen_template,\n",
    "    \n",
    ") -> List[Tuple[str, str]]:\n",
    "    \"\"\"Generate questions.\"\"\"\n",
    "    engine, nodes = list(nodes_dict.items())[0]\n",
    "    if engine == 'gpt-4':\n",
    "        llm = llm_gpt4\n",
    "    else:\n",
    "        llm = llm_claude3\n",
    "    def process_node(idx, node):\n",
    "        cur_context_str = node.get_content(metadata_mode=\"none\")\n",
    "        if \"{few_shot_examples}\" in '\\n'.join([x.content for x in mcq_question_gen_template.message_templates]) and top_k > 0:\n",
    "            arabicmmlu_retriever = arabicmmlu_index.as_retriever(\n",
    "                similarity_top_k=top_k,\n",
    "                embed_model=embed_model,\n",
    "            )\n",
    "            few_shot_examples_str = \"\\n\\n\".join([\n",
    "                x.text for x in arabicmmlu_retriever.retrieve(node.text)\n",
    "            ])\n",
    "        else:\n",
    "            few_shot_examples_str = \"\"\n",
    "\n",
    "        fmt_messages = mcq_question_gen_template.format_messages(\n",
    "            num_questions_per_chunk=num_questions_per_chunk,\n",
    "            context_str=cur_context_str,\n",
    "            few_shot_examples=few_shot_examples_str,\n",
    "        )\n",
    "        try:\n",
    "            chat_response = llm.chat(fmt_messages)\n",
    "            raw_output = chat_response.message.content\n",
    "        except Exception as e:\n",
    "            # add a 2 second sleep and retry\n",
    "            time.sleep(2)\n",
    "            try:\n",
    "                chat_response = llm.chat(fmt_messages)\n",
    "                raw_output = chat_response.message.content\n",
    "            except Exception as e:\n",
    "                raw_output = ''\n",
    "        result_list = str(raw_output).strip().split(delimiter)\n",
    "        # cur_mcq_pairs = [\n",
    "        #     #TODO: make this from the config\n",
    "        #     question.strip().strip('السؤال: ').split(\"الجواب الصحيح: \")\n",
    "        #     for question in result_list if question.strip()\n",
    "        # ]\n",
    "        cur_mcq_pairs = [f'Engine: {engine}' + '\\n\\n' + f'Context: {node.text}\\n\\n' + x.strip() for x in result_list if x.strip()]\n",
    "        \n",
    "        return cur_mcq_pairs\n",
    "    \n",
    "    mcq_pairs = []\n",
    "    batch_size = 10\n",
    "    for i in range(0, len(nodes), batch_size):\n",
    "        mcq_pairs += list(\n",
    "        tqdm(\n",
    "            ThreadPool().imap(\n",
    "                lambda x: process_node(*x),\n",
    "                enumerate(nodes[i:i+batch_size]),\n",
    "            ),\n",
    "        f\"Generating {engine} QA pairs\",\n",
    "        total=batch_size,\n",
    "            )\n",
    "        )\n",
    "        with open(f\"{engine}_MCQs.json\", \"w\") as f:\n",
    "            json.dump(mcq_pairs, f, indent=4, ensure_ascii=False)\n",
    "    # flatten\n",
    "    mcq_pairs = [item for sublist in mcq_pairs for item in sublist]\n",
    "    return mcq_pairs\n",
    "\n",
    "# mcq_pairs = generate_mcq_pairs(\n",
    "#     random_nodes,\n",
    "#     # nodes,\n",
    "#     llm,\n",
    "#     mcq_question_gen_template=mcq_question_gen_template,\n",
    "#     num_questions_per_chunk=4,\n",
    "#     delimiter=\"####\"\n",
    "# )\n",
    "# for q, a in mcq_pairs:\n",
    "#     print(f\"Q: {q}\\nA: {a}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40b26051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling the nodes with a fixed seed\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b7745e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = int(len(nodes)*0.5)\n",
    "gpt4_nodes = nodes[:i]\n",
    "claude3_nodes = nodes[i:]\n",
    "all_nodes = [{'gpt-4': gpt4_nodes}, {'claude-3-opus': claude3_nodes}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f160ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3044, 3045)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gpt4_nodes), len(claude3_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8333691",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_shot_mcq = generate_mcq_pairs(\n",
    "                                nodes, \n",
    "                                mcq_question_gen_template=mcq_question_gen_template,\n",
    "                                num_questions_per_chunk=2,\n",
    "                                top_k=3,\n",
    "                                delimiter=\"####\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thiqatiBot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
